{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_preprocess_dataset_path = \"./data/2023-05-17-15-30-06_after_preprocess_dataset_clean_english_only_new.csv\"\n",
    "topic_result_path = \"./output/topic_result_2023-05-17-15-33-14_1iter.txt\"\n",
    "\n",
    "model_path = \"./models/btm_model_2023-05-17-15-33-14_1iter.pkl\"\n",
    "topic_result_path = \"./output/topic_result_2023-05-17-15-33-14_1iter.txt\"\n",
    "\n",
    "timestamp = '2023-05-17-15-33-14'\n",
    "save_tweets_by_topic_path = f'./output/{timestamp}_tweets_by_topic.csv'\n",
    "save_n_tweets_in_topic = f'./output/{timestamp}_n_tweets_in_topic.csv'\n",
    "save_keywords = f'./output/{timestamp}_keywords.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                          text_clean\n",
       " 0  take within five year expert warn expert expla...\n",
       " 1  although rapidli gain popular also becom issu ...\n",
       " 2  amplifi human potenti school educ board readi ...\n",
       " 3  analyst eran shimoni omer tsarfati detail crea...\n",
       " 4  artificialintellig take within five year exper...,\n",
       " ['take within five year expert warn expert explain bot like domin labor market via  (topic: 3)',\n",
       "  'although rapidli gain popular also becom issu concern openaichatgpt nlp  (topic: 14)',\n",
       "  'amplifi human potenti school educ board readi aiin aiineduc educ  (topic: 4)',\n",
       "  'analyst eran shimoni omer tsarfati detail creat polymorph malwar use plan releas learn purpos  (topic: 17)',\n",
       "  'artificialintellig take within five year expert explain bot like domin labor market uselesseat take vax  (topic: 3)'],\n",
       " (183806, 1),\n",
       " 183806)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "\"\"\"\n",
    "tweets - '.csv' organization of the original corpus\n",
    "tweets_btm - Topic model text file after obtaining the topic classification results, organized as \"document (Topic: 8)\"\n",
    "\"\"\"\n",
    "\n",
    "tweets = pd.read_csv(after_preprocess_dataset_path)\n",
    "tweets_btm = open(topic_result_path).read().splitlines()\n",
    "tweets.head(5), tweets_btm[:5], tweets.shape, len(tweets_btm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>take within five year expert warn expert expla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>although rapidli gain popular also becom issu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amplifi human potenti school educ board readi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>analyst eran shimoni omer tsarfati detail crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>artificialintellig take within five year exper...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  take within five year expert warn expert expla...\n",
       "1  although rapidli gain popular also becom issu ...\n",
       "2  amplifi human potenti school educ board readi ...\n",
       "3  analyst eran shimoni omer tsarfati detail crea...\n",
       "4  artificialintellig take within five year exper..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.rename(columns={\"text_clean\": \"text\"}, inplace=True) # Change the table header to 'text'\n",
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the BTM model file\n",
    "f = open(model_path,'rb')\n",
    "biterm_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0: use,educ,googl,like,openai,make,help,new,way,peopl,write,skill,product,gener,think,chatbot,task,code,say,tool,\n",
      "topic 1: use,like,time,write,make,think,task,educ,gener,tool,replac,student,question,openai,ask,creat,look,learn,differ,skill,\n",
      "topic 2: use,need,ask,time,learn,educ,think,like,make,task,person,openai,futur,good,new,creat,data,im,industri,replac,\n",
      "topic 3: use,like,languag,tool,task,model,train,new,make,openai,skill,learn,mani,know,technolog,industri,content,human,thing,peopl,\n",
      "topic 4: use,like,help,think,task,human,write,need,look,new,replac,peopl,creation,way,openai,content,educ,creat,industri,student,\n",
      "topic 5: use,code,write,ask,educ,human,gener,answer,need,develop,like,skill,artificialintellig,technolog,come,good,dont,question,student,intellig,\n",
      "topic 6: use,gener,model,help,write,train,tool,skill,human,new,team,thing,intellig,im,say,like,build,data,time,creat,\n",
      "topic 7: use,like,make,write,think,educ,technolog,tech,openai,train,skill,peopl,code,world,need,task,learn,time,new,gener,\n",
      "topic 8: use,write,openai,product,googl,tool,help,futur,code,creat,need,time,like,human,make,know,power,intellig,way,task,\n",
      "topic 9: like,gener,educ,intellig,use,train,technolog,data,concern,team,model,openai,artifici,human,tool,make,perform,peopl,languag,task,\n",
      "topic 10: googl,peopl,use,human,data,like,help,train,want,write,think,task,make,new,threat,chang,way,creat,ask,replac,\n",
      "topic 11: like,use,tool,chang,need,model,time,educ,human,write,creat,want,skill,tech,learn,team,read,way,chatbot,problem,\n",
      "topic 12: like,use,tool,new,gener,educ,come,industri,team,creat,openai,task,way,help,think,creation,ask,make,skill,write,\n",
      "topic 13: educ,use,gener,like,think,dont,write,content,know,come,develop,team,openai,better,tech,student,make,way,becom,concern,\n",
      "topic 14: use,team,openai,time,new,educ,like,start,industri,futur,busi,real,content,concern,realli,tool,ask,need,way,make,\n",
      "topic 15: use,gener,industri,write,human,time,replac,learn,peopl,ask,like,im,technolog,make,futur,creat,team,skill,check,tool,\n",
      "topic 16: team,ask,use,write,new,openai,like,make,human,tri,content,educ,good,need,time,answer,look,project,creat,learn,\n",
      "topic 17: use,task,gener,learn,like,write,model,creat,make,new,tool,busi,ask,need,chatbot,content,train,free,potenti,way,\n",
      "topic 18: use,write,like,code,creat,ask,good,skill,make,learn,data,check,task,gener,need,train,new,human,team,look,\n",
      "topic 19: use,make,time,like,think,im,educ,task,question,data,write,good,answer,openai,new,tool,busi,gener,googl,help,\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from operator import itemgetter\n",
    "\n",
    "# vectorize texts\n",
    "vec = CountVectorizer(stop_words='english')\n",
    "tweets_list = [i for item in tweets.values for i in item]\n",
    "X = vec.fit_transform(tweets_list).toarray()\n",
    "\n",
    "# vocab - Get all words\n",
    "vocab = np.array([t for t, i in sorted(vec.vocabulary_.items(),\n",
    "                                     key=itemgetter(1))])\n",
    "\n",
    "# The top probability list of the most likely words for each topic\n",
    "topic_top_prob = biterm_model.phi_wz # phi_wz: [word, topic] Word distribution probability on each topic\n",
    "\n",
    "# Find the topM words for each topic\n",
    "def generate_topic_top_word(topic_top_prob, V, M = 10):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        topic_top_prob - The top probability list of the most likely words for each topic\n",
    "        V [List] - A list of all the words\n",
    "        M - Take the first M words\n",
    "    Returns:\n",
    "        topic_top_word Dict(List[Tuple()]) - The names of the top M words in probability\n",
    "    \"\"\"\n",
    "    topic_top_word = dict()\n",
    "    for z, P_wzi in enumerate(topic_top_prob.T): \n",
    "        \"\"\"\n",
    "            z - z-th topic\n",
    "            P_wzi - The probability distribution of all words on the z-th topic\n",
    "        \"\"\"\n",
    "        topic_top_word[z] = [] # Each topic consists of multiple tuples (word, prob)\n",
    "        V_z_prob = np.sort(P_wzi)[:-(M + 1):-1] # Sort the probability distribution\n",
    "        V_z = np.argsort(P_wzi)[:-(M + 1):-1] # Sort the probability distribution and find the index of the top words\n",
    "        W_z = V[V_z] # Find the name of the word at the top of the list\n",
    "        for prob, word in zip(V_z_prob, W_z): # Form the innermost tuple, meaning tuple(word, prob).\n",
    "            topic_top_word[z].append((word, prob))\n",
    "    return topic_top_word\n",
    "\n",
    "topic_all_words = []\n",
    "# top-M words for each topic\n",
    "topic_top_word = generate_topic_top_word(topic_top_prob, vocab, 20)\n",
    "\n",
    "for i in range(20):\n",
    "    print_str = \"\"\n",
    "    # print_str = f\"topic {i}\"\n",
    "    for j in range(len(topic_top_word[i])):\n",
    "        print_str += f\"{topic_top_word[i][j][0]},\"\n",
    "    topic_all_words.append(print_str)\n",
    "    print(f\"topic {i}: {print_str}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 0/183806\n",
      "finished 1000/183806\n",
      "finished 2000/183806\n",
      "finished 3000/183806\n",
      "finished 4000/183806\n",
      "finished 5000/183806\n",
      "finished 6000/183806\n",
      "finished 7000/183806\n",
      "finished 8000/183806\n",
      "finished 9000/183806\n",
      "finished 10000/183806\n",
      "finished 11000/183806\n",
      "finished 12000/183806\n",
      "finished 13000/183806\n",
      "finished 14000/183806\n",
      "finished 15000/183806\n",
      "finished 16000/183806\n",
      "finished 17000/183806\n",
      "finished 18000/183806\n",
      "finished 19000/183806\n",
      "finished 20000/183806\n",
      "finished 21000/183806\n",
      "finished 22000/183806\n",
      "finished 23000/183806\n",
      "finished 24000/183806\n",
      "finished 25000/183806\n",
      "finished 26000/183806\n",
      "finished 27000/183806\n",
      "finished 28000/183806\n",
      "finished 29000/183806\n",
      "finished 30000/183806\n",
      "finished 31000/183806\n",
      "finished 32000/183806\n",
      "finished 33000/183806\n",
      "finished 34000/183806\n",
      "finished 35000/183806\n",
      "finished 36000/183806\n",
      "finished 37000/183806\n",
      "finished 38000/183806\n",
      "finished 39000/183806\n",
      "finished 40000/183806\n",
      "finished 41000/183806\n",
      "finished 42000/183806\n",
      "finished 43000/183806\n",
      "finished 44000/183806\n",
      "finished 45000/183806\n",
      "finished 46000/183806\n",
      "finished 47000/183806\n",
      "finished 48000/183806\n",
      "finished 49000/183806\n",
      "finished 50000/183806\n",
      "finished 51000/183806\n",
      "finished 52000/183806\n",
      "finished 53000/183806\n",
      "finished 54000/183806\n",
      "finished 55000/183806\n",
      "finished 56000/183806\n",
      "finished 57000/183806\n",
      "finished 58000/183806\n",
      "finished 59000/183806\n",
      "finished 60000/183806\n",
      "finished 61000/183806\n",
      "finished 62000/183806\n",
      "finished 63000/183806\n",
      "finished 64000/183806\n",
      "finished 65000/183806\n",
      "finished 66000/183806\n",
      "finished 67000/183806\n",
      "finished 68000/183806\n",
      "finished 69000/183806\n",
      "finished 70000/183806\n",
      "finished 71000/183806\n",
      "finished 72000/183806\n",
      "finished 73000/183806\n",
      "finished 74000/183806\n",
      "finished 75000/183806\n",
      "finished 76000/183806\n",
      "finished 77000/183806\n",
      "finished 78000/183806\n",
      "finished 79000/183806\n",
      "finished 80000/183806\n",
      "finished 81000/183806\n",
      "finished 82000/183806\n",
      "finished 83000/183806\n",
      "finished 84000/183806\n",
      "finished 85000/183806\n",
      "finished 86000/183806\n",
      "finished 87000/183806\n",
      "finished 88000/183806\n",
      "finished 89000/183806\n",
      "finished 90000/183806\n",
      "finished 91000/183806\n",
      "finished 92000/183806\n",
      "finished 93000/183806\n",
      "finished 94000/183806\n",
      "finished 95000/183806\n",
      "finished 96000/183806\n",
      "finished 97000/183806\n",
      "finished 98000/183806\n",
      "finished 99000/183806\n",
      "finished 100000/183806\n",
      "finished 101000/183806\n",
      "finished 102000/183806\n",
      "finished 103000/183806\n",
      "finished 104000/183806\n",
      "finished 105000/183806\n",
      "finished 106000/183806\n",
      "finished 107000/183806\n",
      "finished 108000/183806\n",
      "finished 109000/183806\n",
      "finished 110000/183806\n",
      "finished 111000/183806\n",
      "finished 112000/183806\n",
      "finished 113000/183806\n",
      "finished 114000/183806\n",
      "finished 115000/183806\n",
      "finished 116000/183806\n",
      "finished 117000/183806\n",
      "finished 118000/183806\n",
      "finished 119000/183806\n",
      "finished 120000/183806\n",
      "finished 121000/183806\n",
      "finished 122000/183806\n",
      "finished 123000/183806\n",
      "finished 124000/183806\n",
      "finished 125000/183806\n",
      "finished 126000/183806\n",
      "finished 127000/183806\n",
      "finished 128000/183806\n",
      "finished 129000/183806\n",
      "finished 130000/183806\n",
      "finished 131000/183806\n",
      "finished 132000/183806\n",
      "finished 133000/183806\n",
      "finished 134000/183806\n",
      "finished 135000/183806\n",
      "finished 136000/183806\n",
      "finished 137000/183806\n",
      "finished 138000/183806\n",
      "finished 139000/183806\n",
      "finished 140000/183806\n",
      "finished 141000/183806\n",
      "finished 142000/183806\n",
      "finished 143000/183806\n",
      "finished 144000/183806\n",
      "finished 145000/183806\n",
      "finished 146000/183806\n",
      "finished 147000/183806\n",
      "finished 148000/183806\n",
      "finished 149000/183806\n",
      "finished 150000/183806\n",
      "finished 151000/183806\n",
      "finished 152000/183806\n",
      "finished 153000/183806\n",
      "finished 154000/183806\n",
      "finished 155000/183806\n",
      "finished 156000/183806\n",
      "finished 157000/183806\n",
      "finished 158000/183806\n",
      "finished 159000/183806\n",
      "finished 160000/183806\n",
      "finished 161000/183806\n",
      "finished 162000/183806\n",
      "finished 163000/183806\n",
      "finished 164000/183806\n",
      "finished 165000/183806\n",
      "finished 166000/183806\n",
      "finished 167000/183806\n",
      "finished 168000/183806\n",
      "finished 169000/183806\n",
      "finished 170000/183806\n",
      "finished 171000/183806\n",
      "finished 172000/183806\n",
      "finished 173000/183806\n",
      "finished 174000/183806\n",
      "finished 175000/183806\n",
      "finished 176000/183806\n",
      "finished 177000/183806\n",
      "finished 178000/183806\n",
      "finished 179000/183806\n",
      "finished 180000/183806\n",
      "finished 181000/183806\n",
      "finished 182000/183806\n",
      "finished 183000/183806\n",
      "          topic                                           keywords  \\\n",
      "156445   topic0  use,educ,googl,like,openai,make,help,new,way,p...   \n",
      "65377    topic0  use,educ,googl,like,openai,make,help,new,way,p...   \n",
      "65381    topic0  use,educ,googl,like,openai,make,help,new,way,p...   \n",
      "165152   topic0  use,educ,googl,like,openai,make,help,new,way,p...   \n",
      "14835    topic0  use,educ,googl,like,openai,make,help,new,way,p...   \n",
      "...         ...                                                ...   \n",
      "83430   topic19  use,make,time,like,think,im,educ,task,question...   \n",
      "83438   topic19  use,make,time,like,think,im,educ,task,question...   \n",
      "148606  topic19  use,make,time,like,think,im,educ,task,question...   \n",
      "51883   topic19  use,make,time,like,think,im,educ,task,question...   \n",
      "38725   topic19  use,make,time,like,think,im,educ,task,question...   \n",
      "\n",
      "                                                    tweet  \n",
      "156445  truli amaz hope get attent need annoy filter r...  \n",
      "65377   googl issu code red team come someth good bett...  \n",
      "65381   googl major challeng hand must effect respond ...  \n",
      "165152  want creat resum grab attent employ look check...  \n",
      "14835   industri increasingli adopt peopl switch oper ...  \n",
      "...                                                   ...  \n",
      "83430   know mani peopl dont like art godsend year pro...  \n",
      "83438   know peopl excit perceiv threat googl think ge...  \n",
      "148606                                  machin come ede    \n",
      "51883   discov futur educ edtech ceo girish singhania ...  \n",
      "38725                      may fail cfa exam save least    \n",
      "\n",
      "[183806 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "\n",
    "reader = open(topic_result_path, \"r\")\n",
    "i = 0\n",
    "for line in reader.readlines():\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"finished {i}/{tweets.shape[0]}\")\n",
    "    row = []\n",
    "\n",
    "    split_line = line.split(\"(\")\n",
    "    doc = split_line[0]\n",
    "    topic_id = int(split_line[1].split(\" \")[1].split(')')[0])\n",
    "    row.append(f\"topic{topic_id}\")\n",
    "    row.append(topic_all_words[topic_id])\n",
    "    row.append(doc)\n",
    "    temp_df = pd.DataFrame([row], columns=['topic', 'keywords', 'tweet'])\n",
    "    df = pd.concat([df, temp_df], ignore_index=True)\n",
    "    i += 1\n",
    "\n",
    "# sort dataframe by 'topic'\n",
    "df_mapping = pd.DataFrame({\n",
    "    'size': ['topic{}'.format(i) for i in range(20)],\n",
    "})\n",
    "sort_mapping = df_mapping.reset_index().set_index('size')\n",
    "\n",
    "df['topic_num'] = df['topic'].map(sort_mapping['index'])\n",
    "\n",
    "df = df.sort_values('topic_num').drop('topic_num', axis=1)\n",
    "print(df)\n",
    "\n",
    "df.to_csv(save_tweets_by_topic_path, sep=',', index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>topic10</th>\n",
       "      <th>topic11</th>\n",
       "      <th>topic12</th>\n",
       "      <th>topic13</th>\n",
       "      <th>topic14</th>\n",
       "      <th>topic15</th>\n",
       "      <th>topic16</th>\n",
       "      <th>topic17</th>\n",
       "      <th>topic18</th>\n",
       "      <th>topic19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13362.0</td>\n",
       "      <td>12884.0</td>\n",
       "      <td>5469.0</td>\n",
       "      <td>21188.0</td>\n",
       "      <td>6513.0</td>\n",
       "      <td>9517.0</td>\n",
       "      <td>10469.0</td>\n",
       "      <td>9924.0</td>\n",
       "      <td>8424.0</td>\n",
       "      <td>8912.0</td>\n",
       "      <td>9307.0</td>\n",
       "      <td>6234.0</td>\n",
       "      <td>8592.0</td>\n",
       "      <td>9882.0</td>\n",
       "      <td>7478.0</td>\n",
       "      <td>5115.0</td>\n",
       "      <td>7563.0</td>\n",
       "      <td>8284.0</td>\n",
       "      <td>7031.0</td>\n",
       "      <td>7658.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic0   topic1  topic2   topic3  topic4  topic5   topic6  topic7  topic8  \\\n",
       "0  13362.0  12884.0  5469.0  21188.0  6513.0  9517.0  10469.0  9924.0  8424.0   \n",
       "\n",
       "   topic9  topic10  topic11  topic12  topic13  topic14  topic15  topic16  \\\n",
       "0  8912.0   9307.0   6234.0   8592.0   9882.0   7478.0   5115.0   7563.0   \n",
       "\n",
       "   topic17  topic18  topic19  \n",
       "0   8284.0   7031.0   7658.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistic the number of every topic (statistic n_tweets_in_topic)\n",
    "total_topic_num = int(df.iloc[-1]['topic'].split('c')[1]) + 1\n",
    "n_tweets_in_topic = pd.DataFrame(np.zeros(total_topic_num).reshape(1, -1))\n",
    "n_tweets_in_topic.columns = ['topic{}'.format(i) for i in range(20)]\n",
    "\n",
    "for i in range(len(df)):\n",
    "    topic_i = df.iloc[i]['topic']\n",
    "    n_tweets_in_topic[topic_i] += 1\n",
    "n_tweets_in_topic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_n_tweets_in_topic\n",
    "n_tweets_in_topic.to_csv(save_n_tweets_in_topic, sep=',', index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword_number</th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>...</th>\n",
       "      <th>topic10</th>\n",
       "      <th>topic11</th>\n",
       "      <th>topic12</th>\n",
       "      <th>topic13</th>\n",
       "      <th>topic14</th>\n",
       "      <th>topic15</th>\n",
       "      <th>topic16</th>\n",
       "      <th>topic17</th>\n",
       "      <th>topic18</th>\n",
       "      <th>topic19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>use</td>\n",
       "      <td>use</td>\n",
       "      <td>use</td>\n",
       "      <td>use</td>\n",
       "      <td>use</td>\n",
       "      <td>use</td>\n",
       "      <td>use</td>\n",
       "      <td>use</td>\n",
       "      <td>use</td>\n",
       "      <td>...</td>\n",
       "      <td>googl</td>\n",
       "      <td>like</td>\n",
       "      <td>like</td>\n",
       "      <td>educ</td>\n",
       "      <td>use</td>\n",
       "      <td>use</td>\n",
       "      <td>team</td>\n",
       "      <td>use</td>\n",
       "      <td>use</td>\n",
       "      <td>use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>educ</td>\n",
       "      <td>like</td>\n",
       "      <td>need</td>\n",
       "      <td>like</td>\n",
       "      <td>like</td>\n",
       "      <td>code</td>\n",
       "      <td>gener</td>\n",
       "      <td>like</td>\n",
       "      <td>write</td>\n",
       "      <td>...</td>\n",
       "      <td>peopl</td>\n",
       "      <td>use</td>\n",
       "      <td>use</td>\n",
       "      <td>use</td>\n",
       "      <td>team</td>\n",
       "      <td>gener</td>\n",
       "      <td>ask</td>\n",
       "      <td>task</td>\n",
       "      <td>write</td>\n",
       "      <td>make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>googl</td>\n",
       "      <td>time</td>\n",
       "      <td>ask</td>\n",
       "      <td>languag</td>\n",
       "      <td>help</td>\n",
       "      <td>write</td>\n",
       "      <td>model</td>\n",
       "      <td>make</td>\n",
       "      <td>openai</td>\n",
       "      <td>...</td>\n",
       "      <td>use</td>\n",
       "      <td>tool</td>\n",
       "      <td>tool</td>\n",
       "      <td>gener</td>\n",
       "      <td>openai</td>\n",
       "      <td>industri</td>\n",
       "      <td>use</td>\n",
       "      <td>gener</td>\n",
       "      <td>like</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>like</td>\n",
       "      <td>write</td>\n",
       "      <td>time</td>\n",
       "      <td>tool</td>\n",
       "      <td>think</td>\n",
       "      <td>ask</td>\n",
       "      <td>help</td>\n",
       "      <td>write</td>\n",
       "      <td>product</td>\n",
       "      <td>...</td>\n",
       "      <td>human</td>\n",
       "      <td>chang</td>\n",
       "      <td>new</td>\n",
       "      <td>like</td>\n",
       "      <td>time</td>\n",
       "      <td>write</td>\n",
       "      <td>write</td>\n",
       "      <td>learn</td>\n",
       "      <td>code</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>openai</td>\n",
       "      <td>make</td>\n",
       "      <td>learn</td>\n",
       "      <td>task</td>\n",
       "      <td>task</td>\n",
       "      <td>educ</td>\n",
       "      <td>write</td>\n",
       "      <td>think</td>\n",
       "      <td>googl</td>\n",
       "      <td>...</td>\n",
       "      <td>data</td>\n",
       "      <td>need</td>\n",
       "      <td>gener</td>\n",
       "      <td>think</td>\n",
       "      <td>new</td>\n",
       "      <td>human</td>\n",
       "      <td>new</td>\n",
       "      <td>like</td>\n",
       "      <td>creat</td>\n",
       "      <td>think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>make</td>\n",
       "      <td>think</td>\n",
       "      <td>educ</td>\n",
       "      <td>model</td>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "      <td>train</td>\n",
       "      <td>educ</td>\n",
       "      <td>tool</td>\n",
       "      <td>...</td>\n",
       "      <td>like</td>\n",
       "      <td>model</td>\n",
       "      <td>educ</td>\n",
       "      <td>dont</td>\n",
       "      <td>educ</td>\n",
       "      <td>time</td>\n",
       "      <td>openai</td>\n",
       "      <td>write</td>\n",
       "      <td>ask</td>\n",
       "      <td>im</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>help</td>\n",
       "      <td>task</td>\n",
       "      <td>think</td>\n",
       "      <td>train</td>\n",
       "      <td>write</td>\n",
       "      <td>gener</td>\n",
       "      <td>tool</td>\n",
       "      <td>technolog</td>\n",
       "      <td>help</td>\n",
       "      <td>...</td>\n",
       "      <td>help</td>\n",
       "      <td>time</td>\n",
       "      <td>come</td>\n",
       "      <td>write</td>\n",
       "      <td>like</td>\n",
       "      <td>replac</td>\n",
       "      <td>like</td>\n",
       "      <td>model</td>\n",
       "      <td>good</td>\n",
       "      <td>educ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>new</td>\n",
       "      <td>educ</td>\n",
       "      <td>like</td>\n",
       "      <td>new</td>\n",
       "      <td>need</td>\n",
       "      <td>answer</td>\n",
       "      <td>skill</td>\n",
       "      <td>tech</td>\n",
       "      <td>futur</td>\n",
       "      <td>...</td>\n",
       "      <td>train</td>\n",
       "      <td>educ</td>\n",
       "      <td>industri</td>\n",
       "      <td>content</td>\n",
       "      <td>start</td>\n",
       "      <td>learn</td>\n",
       "      <td>make</td>\n",
       "      <td>creat</td>\n",
       "      <td>skill</td>\n",
       "      <td>task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>way</td>\n",
       "      <td>gener</td>\n",
       "      <td>make</td>\n",
       "      <td>make</td>\n",
       "      <td>look</td>\n",
       "      <td>need</td>\n",
       "      <td>human</td>\n",
       "      <td>openai</td>\n",
       "      <td>code</td>\n",
       "      <td>...</td>\n",
       "      <td>want</td>\n",
       "      <td>human</td>\n",
       "      <td>team</td>\n",
       "      <td>know</td>\n",
       "      <td>industri</td>\n",
       "      <td>peopl</td>\n",
       "      <td>human</td>\n",
       "      <td>make</td>\n",
       "      <td>make</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>peopl</td>\n",
       "      <td>tool</td>\n",
       "      <td>task</td>\n",
       "      <td>openai</td>\n",
       "      <td>new</td>\n",
       "      <td>develop</td>\n",
       "      <td>new</td>\n",
       "      <td>train</td>\n",
       "      <td>creat</td>\n",
       "      <td>...</td>\n",
       "      <td>write</td>\n",
       "      <td>write</td>\n",
       "      <td>creat</td>\n",
       "      <td>come</td>\n",
       "      <td>futur</td>\n",
       "      <td>ask</td>\n",
       "      <td>tri</td>\n",
       "      <td>new</td>\n",
       "      <td>learn</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>write</td>\n",
       "      <td>replac</td>\n",
       "      <td>person</td>\n",
       "      <td>skill</td>\n",
       "      <td>replac</td>\n",
       "      <td>like</td>\n",
       "      <td>team</td>\n",
       "      <td>skill</td>\n",
       "      <td>need</td>\n",
       "      <td>...</td>\n",
       "      <td>think</td>\n",
       "      <td>creat</td>\n",
       "      <td>openai</td>\n",
       "      <td>develop</td>\n",
       "      <td>busi</td>\n",
       "      <td>like</td>\n",
       "      <td>content</td>\n",
       "      <td>tool</td>\n",
       "      <td>data</td>\n",
       "      <td>write</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>skill</td>\n",
       "      <td>student</td>\n",
       "      <td>openai</td>\n",
       "      <td>learn</td>\n",
       "      <td>peopl</td>\n",
       "      <td>skill</td>\n",
       "      <td>thing</td>\n",
       "      <td>peopl</td>\n",
       "      <td>time</td>\n",
       "      <td>...</td>\n",
       "      <td>task</td>\n",
       "      <td>want</td>\n",
       "      <td>task</td>\n",
       "      <td>team</td>\n",
       "      <td>real</td>\n",
       "      <td>im</td>\n",
       "      <td>educ</td>\n",
       "      <td>busi</td>\n",
       "      <td>check</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>product</td>\n",
       "      <td>question</td>\n",
       "      <td>futur</td>\n",
       "      <td>mani</td>\n",
       "      <td>creation</td>\n",
       "      <td>artificialintellig</td>\n",
       "      <td>intellig</td>\n",
       "      <td>code</td>\n",
       "      <td>like</td>\n",
       "      <td>...</td>\n",
       "      <td>make</td>\n",
       "      <td>skill</td>\n",
       "      <td>way</td>\n",
       "      <td>openai</td>\n",
       "      <td>content</td>\n",
       "      <td>technolog</td>\n",
       "      <td>good</td>\n",
       "      <td>ask</td>\n",
       "      <td>task</td>\n",
       "      <td>answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>gener</td>\n",
       "      <td>openai</td>\n",
       "      <td>good</td>\n",
       "      <td>know</td>\n",
       "      <td>way</td>\n",
       "      <td>technolog</td>\n",
       "      <td>im</td>\n",
       "      <td>world</td>\n",
       "      <td>human</td>\n",
       "      <td>...</td>\n",
       "      <td>new</td>\n",
       "      <td>tech</td>\n",
       "      <td>help</td>\n",
       "      <td>better</td>\n",
       "      <td>concern</td>\n",
       "      <td>make</td>\n",
       "      <td>need</td>\n",
       "      <td>need</td>\n",
       "      <td>gener</td>\n",
       "      <td>openai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>think</td>\n",
       "      <td>ask</td>\n",
       "      <td>new</td>\n",
       "      <td>technolog</td>\n",
       "      <td>openai</td>\n",
       "      <td>come</td>\n",
       "      <td>say</td>\n",
       "      <td>need</td>\n",
       "      <td>make</td>\n",
       "      <td>...</td>\n",
       "      <td>threat</td>\n",
       "      <td>learn</td>\n",
       "      <td>think</td>\n",
       "      <td>tech</td>\n",
       "      <td>realli</td>\n",
       "      <td>futur</td>\n",
       "      <td>time</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>need</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>creat</td>\n",
       "      <td>creat</td>\n",
       "      <td>industri</td>\n",
       "      <td>content</td>\n",
       "      <td>good</td>\n",
       "      <td>like</td>\n",
       "      <td>task</td>\n",
       "      <td>know</td>\n",
       "      <td>...</td>\n",
       "      <td>chang</td>\n",
       "      <td>team</td>\n",
       "      <td>creation</td>\n",
       "      <td>student</td>\n",
       "      <td>tool</td>\n",
       "      <td>creat</td>\n",
       "      <td>answer</td>\n",
       "      <td>content</td>\n",
       "      <td>train</td>\n",
       "      <td>tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>task</td>\n",
       "      <td>look</td>\n",
       "      <td>data</td>\n",
       "      <td>content</td>\n",
       "      <td>educ</td>\n",
       "      <td>dont</td>\n",
       "      <td>build</td>\n",
       "      <td>learn</td>\n",
       "      <td>power</td>\n",
       "      <td>...</td>\n",
       "      <td>way</td>\n",
       "      <td>read</td>\n",
       "      <td>ask</td>\n",
       "      <td>make</td>\n",
       "      <td>ask</td>\n",
       "      <td>team</td>\n",
       "      <td>look</td>\n",
       "      <td>train</td>\n",
       "      <td>new</td>\n",
       "      <td>busi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>code</td>\n",
       "      <td>learn</td>\n",
       "      <td>im</td>\n",
       "      <td>human</td>\n",
       "      <td>creat</td>\n",
       "      <td>question</td>\n",
       "      <td>data</td>\n",
       "      <td>time</td>\n",
       "      <td>intellig</td>\n",
       "      <td>...</td>\n",
       "      <td>creat</td>\n",
       "      <td>way</td>\n",
       "      <td>make</td>\n",
       "      <td>way</td>\n",
       "      <td>need</td>\n",
       "      <td>skill</td>\n",
       "      <td>project</td>\n",
       "      <td>free</td>\n",
       "      <td>human</td>\n",
       "      <td>gener</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>say</td>\n",
       "      <td>differ</td>\n",
       "      <td>industri</td>\n",
       "      <td>thing</td>\n",
       "      <td>industri</td>\n",
       "      <td>student</td>\n",
       "      <td>time</td>\n",
       "      <td>new</td>\n",
       "      <td>way</td>\n",
       "      <td>...</td>\n",
       "      <td>ask</td>\n",
       "      <td>chatbot</td>\n",
       "      <td>skill</td>\n",
       "      <td>becom</td>\n",
       "      <td>way</td>\n",
       "      <td>check</td>\n",
       "      <td>creat</td>\n",
       "      <td>potenti</td>\n",
       "      <td>team</td>\n",
       "      <td>googl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>tool</td>\n",
       "      <td>skill</td>\n",
       "      <td>replac</td>\n",
       "      <td>peopl</td>\n",
       "      <td>student</td>\n",
       "      <td>intellig</td>\n",
       "      <td>creat</td>\n",
       "      <td>gener</td>\n",
       "      <td>task</td>\n",
       "      <td>...</td>\n",
       "      <td>replac</td>\n",
       "      <td>problem</td>\n",
       "      <td>write</td>\n",
       "      <td>concern</td>\n",
       "      <td>make</td>\n",
       "      <td>tool</td>\n",
       "      <td>learn</td>\n",
       "      <td>way</td>\n",
       "      <td>look</td>\n",
       "      <td>help</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Keyword_number   topic0    topic1    topic2     topic3    topic4  \\\n",
       "1                1      use       use       use        use       use   \n",
       "2                2     educ      like      need       like      like   \n",
       "3                3    googl      time       ask    languag      help   \n",
       "4                4     like     write      time       tool     think   \n",
       "5                5   openai      make     learn       task      task   \n",
       "6                6     make     think      educ      model     human   \n",
       "7                7     help      task     think      train     write   \n",
       "8                8      new      educ      like        new      need   \n",
       "9                9      way     gener      make       make      look   \n",
       "10              10    peopl      tool      task     openai       new   \n",
       "11              11    write    replac    person      skill    replac   \n",
       "12              12    skill   student    openai      learn     peopl   \n",
       "13              13  product  question     futur       mani  creation   \n",
       "14              14    gener    openai      good       know       way   \n",
       "15              15    think       ask       new  technolog    openai   \n",
       "16              16  chatbot     creat     creat   industri   content   \n",
       "17              17     task      look      data    content      educ   \n",
       "18              18     code     learn        im      human     creat   \n",
       "19              19      say    differ  industri      thing  industri   \n",
       "20              20     tool     skill    replac      peopl   student   \n",
       "\n",
       "                topic5    topic6     topic7    topic8  ... topic10  topic11  \\\n",
       "1                  use       use        use       use  ...   googl     like   \n",
       "2                 code     gener       like     write  ...   peopl      use   \n",
       "3                write     model       make    openai  ...     use     tool   \n",
       "4                  ask      help      write   product  ...   human    chang   \n",
       "5                 educ     write      think     googl  ...    data     need   \n",
       "6                human     train       educ      tool  ...    like    model   \n",
       "7                gener      tool  technolog      help  ...    help     time   \n",
       "8               answer     skill       tech     futur  ...   train     educ   \n",
       "9                 need     human     openai      code  ...    want    human   \n",
       "10             develop       new      train     creat  ...   write    write   \n",
       "11                like      team      skill      need  ...   think    creat   \n",
       "12               skill     thing      peopl      time  ...    task     want   \n",
       "13  artificialintellig  intellig       code      like  ...    make    skill   \n",
       "14           technolog        im      world     human  ...     new     tech   \n",
       "15                come       say       need      make  ...  threat    learn   \n",
       "16                good      like       task      know  ...   chang     team   \n",
       "17                dont     build      learn     power  ...     way     read   \n",
       "18            question      data       time  intellig  ...   creat      way   \n",
       "19             student      time        new       way  ...     ask  chatbot   \n",
       "20            intellig     creat      gener      task  ...  replac  problem   \n",
       "\n",
       "     topic12  topic13   topic14    topic15  topic16  topic17 topic18   topic19  \n",
       "1       like     educ       use        use     team      use     use       use  \n",
       "2        use      use      team      gener      ask     task   write      make  \n",
       "3       tool    gener    openai   industri      use    gener    like      time  \n",
       "4        new     like      time      write    write    learn    code      like  \n",
       "5      gener    think       new      human      new     like   creat     think  \n",
       "6       educ     dont      educ       time   openai    write     ask        im  \n",
       "7       come    write      like     replac     like    model    good      educ  \n",
       "8   industri  content     start      learn     make    creat   skill      task  \n",
       "9       team     know  industri      peopl    human     make    make  question  \n",
       "10     creat     come     futur        ask      tri      new   learn      data  \n",
       "11    openai  develop      busi       like  content     tool    data     write  \n",
       "12      task     team      real         im     educ     busi   check      good  \n",
       "13       way   openai   content  technolog     good      ask    task    answer  \n",
       "14      help   better   concern       make     need     need   gener    openai  \n",
       "15     think     tech    realli      futur     time  chatbot    need       new  \n",
       "16  creation  student      tool      creat   answer  content   train      tool  \n",
       "17       ask     make       ask       team     look    train     new      busi  \n",
       "18      make      way      need      skill  project     free   human     gener  \n",
       "19     skill    becom       way      check    creat  potenti    team     googl  \n",
       "20     write  concern      make       tool    learn      way    look      help  \n",
       "\n",
       "[20 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# statistic the keywords of every topic\n",
    "total_topic_num = int(df.iloc[-1]['topic'].split('c')[1]) + 1\n",
    "\n",
    "columns_df = ['Keyword_number']\n",
    "columns_df.extend(['topic{}'.format(i) for i in range(20)])\n",
    "keywords_df = pd.DataFrame(columns=columns_df, index=np.arange(1, total_topic_num+1))\n",
    "keywords_df['Keyword_number'] = np.arange(1, total_topic_num + 1)\n",
    "\n",
    "# top-M words for each topic\n",
    "topic_top_word = generate_topic_top_word(topic_top_prob, vocab, total_topic_num)\n",
    "for i in range(total_topic_num):\n",
    "    topic_str = 'topic' + str(i)\n",
    "    keywords_num = len(topic_top_word[i])\n",
    "    keywords_list = []\n",
    "    for j in range(keywords_num):\n",
    "        keywords_list.append(topic_top_word[i][j][0])\n",
    "    keywords_df[topic_str] = keywords_list\n",
    "    \n",
    "keywords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_n_tweets_in_topic\n",
    "keywords_df.to_csv(save_keywords, sep=',', index=False,header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('btm': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ef337ba82591e8ad80352ba8fbdba14af60eec38c8eaf90bf9232c7a9f4fb1af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
